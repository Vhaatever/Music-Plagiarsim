{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vhaatever/Music-Plagiarsim/blob/main/Music_Plagiarism_using_analytical_schema.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyvoHpc8cIYG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import sklearn\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.manifold import LocallyLinearEmbedding\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTDOZ4QBsNzJ"
      },
      "outputs": [],
      "source": [
        "#Applying LLE\n",
        "def apply_LLE(Xdb):\n",
        "  embedding = LocallyLinearEmbedding(n_components=3)\n",
        "  X_transformed = embedding.fit_transform(Xdb.transpose())\n",
        "  return X_transformed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjN3RITcgscU"
      },
      "outputs": [],
      "source": [
        "#Feature extraction\n",
        "def extract_all(name,sampling_rate):\n",
        "  x,sr= librosa.load(name,sampling_rate)\n",
        "  x=x\n",
        "  output=spectrogram(x)[0,:]\n",
        "  output=np.vstack((output, centroid(x, sampling_rate)))\n",
        "  output=np.vstack((output, roll_off(x)))\n",
        "  output=np.vstack((output, MFCC(x)))\n",
        "  output=np.vstack((output, chromatogram(x, sampling_rate)))\n",
        "  #output=np.vstack((output, FWHM(x, sampling_rate)))\n",
        "  return output.transpose()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIhXe9Z3ftYM"
      },
      "outputs": [],
      "source": [
        "class Music:\n",
        "  def __init__(self, path, input_index):\n",
        "   '''\n",
        "   :param name: address of the music\n",
        "   '''\n",
        "   if path is None:\n",
        "    return\n",
        "   self.index=input_index\n",
        "   self.name = path\n",
        "   self.features =extract_all(self.name,sampling_rate)\n",
        "   '''\n",
        "   self.spectrogram = self.features[:,0]\n",
        "   self.centroid = self.features[:,1]\n",
        "   self.roll_off = self.features[:,2]\n",
        "   self.MFCC = self.features[:,3]\n",
        "   self.chromatogram = self.features[:,4]\n",
        "   '''\n",
        "   #self.FWHM = self.features[:,5]\n",
        "   print(self.index)\n",
        "\n",
        "  def split_into_pieces(self, word_length ,overlap_rate):\n",
        "    pieces=[]\n",
        "    self.word_length=word_length\n",
        "    self.overlap_rate=overlap_rate\n",
        "    overlap=int(word_length*overlap_rate)\n",
        "    jump= word_length-overlap\n",
        "    idx=0\n",
        "    while(idx < len(self.features[:,0])):\n",
        "      if idx + word_length <= len(self.features[:,0]):\n",
        "        pieces.append(self.features[idx:idx+word_length])\n",
        "      else:\n",
        "        pieces.append(self.features[idx:])\n",
        "      idx += jump\n",
        "    self.pieces=pieces\n",
        "    self.num_words=len(self.pieces)\n",
        "    self.num_letters=len(self.pieces[0])\n",
        "    self.num_features=len(self.pieces[0][0])\n",
        "\n",
        "  \n",
        "  def take_sub_string(self, num):\n",
        "    self.pieces=self.pieces[:num]\n",
        "    self.num_words=len(self.pieces)\n",
        "    self.num_letters=len(self.pieces[0])\n",
        "    self.num_features=len(self.pieces[0][0])\n",
        "    print(\"Number of words- %d\" % len(self.pieces))\n",
        "   # print(pieces)\n",
        "    print(\"Number of letters- %d\" % len(self.pieces[0]))\n",
        "    #print(pieces[0])\n",
        "    print(\"Number of features- %d\" % len(self.pieces[0][0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wd8qTsA6rq8g"
      },
      "outputs": [],
      "source": [
        "#Individual features \n",
        "def spectrogram(x):\n",
        "  X = librosa.stft(x)\n",
        "  Xdb = librosa.amplitude_to_db(abs(X))\n",
        "  X_transformed=apply_LLE(Xdb)\n",
        "  return X_transformed.transpose()\n",
        "\n",
        "def centroid(x, sampling_rate):\n",
        "  spectral_centroids = librosa.feature.spectral_centroid(x, sr=sampling_rate)[0]\n",
        "  scaler.fit_transform(spectral_centroids.reshape(-1,1))\n",
        "  spectral_centroids = scaler.transform(spectral_centroids.reshape(-1,1))\n",
        "\n",
        "  return spectral_centroids.transpose()\n",
        "\n",
        "def roll_off(x):\n",
        "  spectral_rolloff = librosa.feature.spectral_rolloff(x+0.01, sr=sampling_rate)[0]\n",
        "  scaler.fit_transform(spectral_rolloff.reshape(-1,1))\n",
        "  spectral_rolloff = scaler.transform(spectral_rolloff.reshape(-1,1))\n",
        "\n",
        "  return spectral_rolloff.transpose()\n",
        "\n",
        "def FWHM(x, sampling_rate):\n",
        "  spectral_bandwidth_2 = librosa.feature.spectral_bandwidth(x+0.01, sr=sampling_rate)[0]\n",
        "  spectral_bandwidth_3 = librosa.feature.spectral_bandwidth(x+0.01, sr=sampling_rate, p=3)[0]\n",
        "  spectral_bandwidth_4 = librosa.feature.spectral_bandwidth(x+0.01, sr=sampling_rate, p=4)[0]\n",
        "  output=np.empty_like(spectral_bandwidth_2)\n",
        "  output=np.vstack((output, spectral_bandwidth_2))\n",
        "  output=np.vstack((output, spectral_bandwidth_3))\n",
        "  output=np.vstack((output, spectral_bandwidth_4))\n",
        "  output= apply_LLE(output)\n",
        "  return output.transpose()\n",
        "\n",
        "def MFCC(x):\n",
        "  mfccs = librosa.feature.mfcc(x)\n",
        "  mfccs = apply_LLE(mfccs)\n",
        "  scaler.fit_transform(mfccs)\n",
        "  mfccs = scaler.transform(mfccs)\n",
        "\n",
        "  return mfccs.transpose()\n",
        "\n",
        "def chromatogram(x, sampling_rate):\n",
        "  chromagram = librosa.feature.chroma_stft(x, sr=sampling_rate)\n",
        "  chromagram = apply_LLE(chromagram)\n",
        "  scaler.fit_transform(chromagram)\n",
        "  chromagram = scaler.transform(chromagram)\n",
        "  return chromagram.transpose()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cTKZ42TKWa8"
      },
      "outputs": [],
      "source": [
        "  #Edit Distance....... \n",
        "def distance_song(song1, song2, feature_weights):\n",
        "    answer=[]\n",
        "    row=0\n",
        "    col=0\n",
        "    for i in range(len(feature_weights)):\n",
        "      feature_weight= feature_weights[i]\n",
        "      num_word1= song1.num_words\n",
        "      num_word2= song2.num_words\n",
        "      bipartite_matrix=[[0]*num_word2]*num_word1\n",
        "      \n",
        "      for x in range(num_word1):\n",
        "        word1=np.array(song1.pieces[x])\n",
        "        for y in range(num_word2):\n",
        "          word2=np.array(song2.pieces[y])\n",
        "          bipartite_matrix[x][y]=edit_distance_dp(word1[:,i], word2[:,i], feature_weight)\n",
        "      row,col= linear_sum_assignment(bipartite_matrix)\n",
        "      answer.append(np.array(bipartite_matrix)[row,col].sum())\n",
        "    return answer\n",
        "                                                        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BsILcjAvkwh9"
      },
      "outputs": [],
      "source": [
        "def edit_distance_dp(seq1, seq2, feature_weight):\n",
        "\n",
        "  cost = np.zeros((len(seq1), len(seq2)))\n",
        "\n",
        "  for row in range(len(seq1)):\n",
        "    for col in range(len(seq2)):\n",
        "      ins_cost = 5*feature_weight*(abs(seq1[row]))\n",
        "      del_cost = 5*feature_weight*(abs(seq2[col]))\n",
        "      sub_cost = 0.1*feature_weight*(abs(seq1[row]-seq2[col]))\n",
        "      if seq1[row-1] == seq2[col-1]:\n",
        "        cost[row][col] = cost[row-1][col-1]\n",
        "      else: \n",
        "        insertion_cost = cost[row-1][col] + ins_cost\n",
        "        deletion_cost = cost[row][col-1] + del_cost\n",
        "        substitution_cost = cost[row-1][col-1] + sub_cost\n",
        "        # calculate the minimum cost\n",
        "        cost[row][col]= min(insertion_cost, deletion_cost, substitution_cost)\n",
        "        # get the operation\n",
        "  return cost[len(seq1)-1, len(seq2)-1]          "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7O13HhPmFK5"
      },
      "outputs": [],
      "source": [
        "#Driver class\n",
        "data_path='drive/MyDrive/A SOP Songs/'\n",
        "sampling_rate=20000\n",
        "max_songs=6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hq7ZO20t6sb",
        "outputId": "bc962a1a-d3bc-4979-eae9-f7ebf7d0ae1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "Elvis Presley - Marguerita 1963. - Feature Extracted\n",
            "Time taken to extract features 30.34813117980957\n",
            "1\n",
            "Oasis - Whatever (Official Video). - Feature Extracted\n",
            "Time taken to extract features 198.56486821174622\n",
            "2\n",
            "How Sweet to Be an Idiot (2007 Remaster). - Feature Extracted\n",
            "Time taken to extract features 20.393435955047607\n",
            "3\n",
            "Matt Cardle - Amazing. - Feature Extracted\n",
            "Time taken to extract features 36.11031699180603\n",
            "4\n",
            "Ed Sheeran - Photograph (Official Music Video). - Feature Extracted\n",
            "Time taken to extract features 50.23399496078491\n",
            "5\n",
            "Rappin 4 Tay - Players Club. - Feature Extracted\n",
            "Time taken to extract features 73.91081237792969\n",
            "Time taken for feature extraction409.561559677124\n",
            "Average Time taken for feature extraction68.26025994618733\n"
          ]
        }
      ],
      "source": [
        "files = os.listdir(data_path)\n",
        "file_num = len(files)\n",
        "musics = []\n",
        "i=0\n",
        "time_feature=0\n",
        "for file in files:\n",
        "  if(i<max_songs):\n",
        "    start=time.time()\n",
        "    music = Music(data_path + file, i)\n",
        "    end=time.time()\n",
        "    print(file[:-3]+\" - Feature Extracted\")\n",
        "    print(f\"Time taken to extract features {end - start}\")\n",
        "    time_feature=time_feature+(end-start)\n",
        "    musics.append(music)\n",
        "    i=i+1\n",
        "print(f\"Time taken for feature extraction{time_feature}\")\n",
        "print(f\"Average Time taken for feature extraction{time_feature/i}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGbYYHv7gRl2",
        "outputId": "a4e9188b-2862-45ea-f5c1-5e5fa2862f55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time taken to split the strings is 0.0004146099090576172\n",
            "Number of words- 25\n",
            "Number of letters- 50\n",
            "Number of features- 9\n",
            "Time taken to split the strings is 0.0008423328399658203\n",
            "Number of words- 25\n",
            "Number of letters- 50\n",
            "Number of features- 9\n",
            "Time taken to split the strings is 0.0003848075866699219\n",
            "Number of words- 25\n",
            "Number of letters- 50\n",
            "Number of features- 9\n",
            "Time taken to split the strings is 0.0005519390106201172\n",
            "Number of words- 25\n",
            "Number of letters- 50\n",
            "Number of features- 9\n",
            "Time taken to split the strings is 0.0005812644958496094\n",
            "Number of words- 25\n",
            "Number of letters- 50\n",
            "Number of features- 9\n",
            "Time taken to split the strings is 0.0005714893341064453\n",
            "Number of words- 25\n",
            "Number of letters- 50\n",
            "Number of features- 9\n",
            "Elvis Presley - Marguerita 1963. Compared with Oasis - Whatever (Official Video).\n"
          ]
        }
      ],
      "source": [
        "Distance = [[0 for i in range(i)] for j in range(i)]\n",
        "time_distance=0\n",
        "max_songs=8\n",
        "spectrogram_weight=0.4\n",
        "mfcc_weight=0.5\n",
        "feature_weights=[spectrogram_weight,spectrogram_weight,spectrogram_weight, 0.3,0.2,mfcc_weight,mfcc_weight,mfcc_weight,0.1]\n",
        "reference_list=['spectrogram, centroid, roll_off, MFCC, chromatogram']\n",
        "num_letter=50\n",
        "overlap_rate=0.05\n",
        "words_chosen=25\n",
        "for song in musics:\n",
        "  start=time.time()\n",
        "  song.split_into_pieces(num_letter,overlap_rate)\n",
        "  end=time.time()\n",
        "  print(f\"Time taken to split the strings is {end - start}\")\n",
        "  song.take_sub_string(words_chosen)\n",
        "for song1 in musics:\n",
        "  for song2 in musics:\n",
        "    if(song1!=song2 and song1.index<max_songs and song2.index<max_songs):\n",
        "      print(song1.name[26:-3] + \" Compared with \" + song2.name[26:-3])\n",
        "      start=time.time()\n",
        "      cost_songs= distance_song(song1, song2, feature_weights)\n",
        "      cost=math.sqrt(np.mean(np.array(cost_songs)**2))\n",
        "      end=time.time()\n",
        "      print(f\"Total Time taken for this comparison {end - start}\")\n",
        "      time_distance=time_distance+(end-start)\n",
        "      print(f\"The distance between the the two songs along the difference matrix is {cost}\")    \n",
        "      if(song1.index!=song2.index):\n",
        "        Distance[song1.index][song2.index]=cost\n",
        "print(f\"Time taken to calculate the distance {time_distance}\")\n",
        "print(f\"Average Time taken to calculate one distance {time_distance/i}\")\n",
        "print(\"This is the distance\")\n",
        "print(\"************\")\n",
        "print(\"************\")\n",
        "print(\"************\")\n",
        "for j in range(i):\n",
        "  print(str(j)+\": \"+ musics[j].name[26:-3])\n",
        "print('\\n'.join('{}: {}'.format(*k) for k in enumerate(Distance)))\n",
        "\n",
        "Final_Distance= np.sqrt((np.array(Distance))**2+(np.array(Distance)**2).transpose())\n",
        "print(\"final\")\n",
        "for j in range(i):\n",
        "  print(str(j)+\": \"+ musics[j].name[26:-3])\n",
        "print(Final_Distance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zh3xbd58wcg_"
      },
      "outputs": [],
      "source": [
        "def find_rank(Final_distance):\n",
        "  num_rows= len(Final_distance)\n",
        "  for rows in range(num_rows):\n",
        "    Song1= Final_distance[rows,:]\n",
        "    Song2=Song1.copy()\n",
        "    Song1= np.delete(Song1, rows)\n",
        "    element= min(Song1)\n",
        "    print(element)\n",
        "    print(Song2)\n",
        "    out=find(element,Song2)\n",
        "    print(\"Song :\" +str(rows)+\" Plagiarized to song :\" +str(out))\n",
        "\n",
        "\n",
        "def find(element, matrix):\n",
        "  for i in range(len(matrix)):\n",
        "    if matrix[i] == element:\n",
        "      return i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fb3E5Ypq9sYW"
      },
      "outputs": [],
      "source": [
        "find_rank(Final_Distance)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}